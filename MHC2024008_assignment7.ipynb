{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vkavyasree732/Repository1/blob/main/MHC2024008_assignment7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvEOiYhHFxQC",
        "outputId": "6767de83-8e49-400c-d1f4-c2ffc44de462"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:04<00:00, 35.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import copy\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "batch_size = 128\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = x.view(-1, 128 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "net = CNN().to(device)\n"
      ],
      "metadata": {
        "id": "snDfMor4HDkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, optimizer, criterion, num_epochs=10):\n",
        "    model.to(device)\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for inputs, labels in trainloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f'Epoch {epoch+1}, Loss: {running_loss / len(trainloader):.4f}, Accuracy: {accuracy:.2f}%')\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "z-UpcbuqHHNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_model = CNN().to(device)\n",
        "initial_weights = copy.deepcopy(initial_model.state_dict())"
      ],
      "metadata": {
        "id": "vUz8VjLTHHYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "momentum_values = [0.5, 0.9, 0.99]\n",
        "for momentum in momentum_values:\n",
        "    print(f'Training with SGD, Momentum: {momentum}')\n",
        "    model = CNN().to(device)\n",
        "    model.load_state_dict(initial_weights)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=momentum)\n",
        "    train_model(model, optimizer, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3ZQ08iYHR27",
        "outputId": "d73599d0-3062-452f-8240-3ef53ffa30f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with SGD, Momentum: 0.5\n",
            "Epoch 1, Loss: 1.4173, Accuracy: 49.48%\n",
            "Epoch 2, Loss: 1.0267, Accuracy: 64.06%\n",
            "Epoch 3, Loss: 0.8748, Accuracy: 69.54%\n",
            "Epoch 4, Loss: 0.7781, Accuracy: 73.12%\n",
            "Epoch 5, Loss: 0.7017, Accuracy: 75.86%\n",
            "Epoch 6, Loss: 0.6428, Accuracy: 77.73%\n",
            "Epoch 7, Loss: 0.5861, Accuracy: 79.85%\n",
            "Epoch 8, Loss: 0.5367, Accuracy: 81.60%\n",
            "Epoch 9, Loss: 0.4906, Accuracy: 83.24%\n",
            "Epoch 10, Loss: 0.4476, Accuracy: 84.68%\n",
            "Training with SGD, Momentum: 0.9\n",
            "Epoch 1, Loss: 1.2428, Accuracy: 55.19%\n",
            "Epoch 2, Loss: 0.8463, Accuracy: 70.12%\n",
            "Epoch 3, Loss: 0.6938, Accuracy: 75.55%\n",
            "Epoch 4, Loss: 0.5854, Accuracy: 79.53%\n",
            "Epoch 5, Loss: 0.4990, Accuracy: 82.41%\n",
            "Epoch 6, Loss: 0.4283, Accuracy: 84.89%\n",
            "Epoch 7, Loss: 0.3509, Accuracy: 87.78%\n",
            "Epoch 8, Loss: 0.2960, Accuracy: 89.76%\n",
            "Epoch 9, Loss: 0.2397, Accuracy: 91.69%\n",
            "Epoch 10, Loss: 0.1852, Accuracy: 93.60%\n",
            "Training with SGD, Momentum: 0.99\n",
            "Epoch 1, Loss: 1.4707, Accuracy: 47.58%\n",
            "Epoch 2, Loss: 1.0365, Accuracy: 63.52%\n",
            "Epoch 3, Loss: 0.8186, Accuracy: 71.56%\n",
            "Epoch 4, Loss: 0.6922, Accuracy: 76.02%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for momentum in momentum_values:\n",
        "    print(f'Training with NAG, Momentum: {momentum}')\n",
        "    model = CNN().to(device)\n",
        "    model.load_state_dict(initial_weights)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=momentum, nesterov=True)\n",
        "    train_model(model, optimizer, criterion)"
      ],
      "metadata": {
        "id": "Vm4gYw4OHVFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training with Adam')\n",
        "model = CNN().to(device)\n",
        "model.load_state_dict(initial_weights)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "train_model(model, optimizer, criterion)"
      ],
      "metadata": {
        "id": "lpw0S1jeIDAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training with RMSProp')\n",
        "model = CNN().to(device)\n",
        "model.load_state_dict(initial_weights)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n",
        "train_model(model, optimizer, criterion)"
      ],
      "metadata": {
        "id": "VawaApq6IGtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "optimizers = ['SGD (0.5)', 'SGD (0.9)', 'SGD (0.99)', 'NAG (0.5)', 'NAG (0.9)', 'NAG (0.99)', 'Adam', 'RMSprop']\n",
        "accuracies = [83.91,91.88, 87.03,83.43, 93.80, 91.17, 92.33, 87.36]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(optimizers, accuracies, color='skyblue')\n",
        "plt.xlabel(\"Optimizers\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.title(\"Accuracy Comparison of Different Optimizers\")\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jH7M_XASIOqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis of Convergence and Generalization\n",
        "\n",
        "1)Which Optimizer Converges Faster?\n",
        "\n",
        "NAG with Momentum 0.9 achieved 93.80% accuracy in 10 epochs, showing the fastest convergence.\n",
        "Adam also converged quickly, reaching 92.33% in 10 epochs.\n",
        "RMSProp had slower convergence, reaching 87.36%.\n",
        "SGD (Momentum 0.5, 0.9, 0.99) took longer to reach high accuracy compared to NAG and Adam.\n",
        "\n",
        "2)Which Optimizer Generalizes Better?\n",
        "\n",
        "NAG with Momentum 0.9 and Adam performed best in training. However, Adam is known for overfitting, while NAG often generalizes better.\n",
        "SGD with Momentum 0.9 showed good stability, but not as high accuracy as NAG.\n",
        "RMSProp is typically better for non-stationary data, but in this case, it underperformed compared to others.\n",
        "Impact of Increasing Momentum on Training Stability\n",
        "Momentum 0.5: Stable but slower convergence.\n",
        "Momentum 0.9: Optimal balance between speed and stability.\n",
        "Momentum 0.99: Faster convergence but may overshoot or cause oscillations."
      ],
      "metadata": {
        "id": "tjJAhdlgIbX0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t0SDXN9MIyAJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}